# Automated Theorem Prover
[阅读中文版本](README_zh.md)
### Introduction

This project is an intelligent tool designed to automatically prove mathematical problems. It combines the power of Large Language Models (LLMs) with sophisticated proving strategies to automate the entire workflow, from problem analysis to final proof generation.

### Architecture

The tool utilizes a three-model architecture to ensure a rigorous and efficient proving process:

1.  **Init Model:**
    * Receives a mathematical problem as input from the user.
    * Analyzes the problem and searches for relevant background knowledge and core theorems.
    * Stores the problem's natural language expression alongside its formal Lean language representation to prepare for the proving stage.

2.  **Prover Model:**
    * Takes the data processed by the Init Model.
    * Executes the core reasoning and proving tasks based on the provided theorems and formal problem statement, generating the steps of the proof.

3.  **Agent Model:**
    * Reviews and summarizes the proof generated by the Prover Model.
    * Constructs and dynamically updates a "Proof Tree," pruning inefficient or invalid branches as needed.
    * Filters and saves the most satisfactory and reliable final proof.

---

### Installation Guide (Windows)

#### 1. Clone the Repository

```bash
git clone <the_repository_url>
cd LEL
````

#### 2\. Install Environment & Dependencies

We recommend using [Pixi](https://github.com/prefix-dev/pixi/releases/latest/download/pixi-x86_64-pc-windows-msvc.msi) for environment management, which offers an experience similar to `conda`.

After navigating to the project directory, activate the environment and install all dependencies with Pixi:

```bash
pixi shell
```

#### 3\. Configure API Keys

You need to provide the necessary API keys to enable the full functionality of the models.

First, create the environment file by copying the template:

```bash
copy .env_template .env
```

Next, edit the new `.env` file and fill in your API keys.

#### 4\. Run the Project

Once the configuration is complete, open and run `main.ipynb` to get started.

-----

### Prerequisites and Important Notes

1.  **Network Environment:** Many features of this tool (like model API calls and web searches) require an international internet connection. Please ensure your network environment is properly configured.

2.  **Lean Environment:**

      * It is crucial to have the Lean environment installed correctly. You can quickly install it using the following command:
        ```bash
        pixi shell
        leanup install
        ```
      * **On first launch**, the Lean interactive server may take **180 to 200 minutes** to initialize.
      * Please ensure you have **at least 10GB of available RAM** when running the Lean server.

3.  **Required API Keys:**

      * **[Gemini](https://aistudio.google.com/app/apikey):** Offers a free tier.
      * **[Open Router](https://openrouter.ai/settings/keys):** Pay-as-you-go, supports various payment methods.
      * **[DashScope](https://dashscope.console.aliyun.com/apiKey):** Provided by Alibaba Cloud, offers a free quota.
      * **[Lean Explore](https://www.leanexplore.com/login?redirect=/api-keys):** Free.

4.  **Optional API Keys:**

      * **[Mineru](https://mineru.net/apiManage):** Required if you need to convert PDF documents into Markdown and sync them to the vector knowledge base. This service is free but may require a network environment based in mainland China. After configuration, you can call the `vec_store.sync_md(r".\src\src_pdf")` function.

-----

### Feature Highlights

1.  **Automated Knowledge Base Management:**
    On each run, the tool automatically scans the knowledge base directory, parsing new `.md` files and syncing their content into the vector database for continuous learning.

2.  **Parallel Model Calls:**
    When invoking the prover, you can specify a list of models to perform parallel inference, boosting both efficiency and the probability of success. For example:

    ```python
    modelName = ["deepseek/deepseek-prover-v2" for i in range(2)]
    ```

3.  **Flexible Model Switching:**
    If your free Gemini quota is exhausted, you can easily switch to an alternative model like Qwen (from Tongyi):

    ```python
    llm = ChatTongyi(model="qwen-max", temperature=0.0)
    ```

### Troubleshooting

1.  **Problem: Failed to import `duckduckgo_search`.**
      * **Cause:** The `duckduckgo_search` library package was renamed to `ddgs`, but the `langchain` framework may not have been updated accordingly.
      * **Solution:** Manually edit the `langchain` dependency file. The typical file path is `.pixi\envs\default\Lib\site-packages\langchain_community\utilities\duckduckgo_search.py`. Open the file and replace the old package name with `ddgs`.

-----

### How to Contribute

We welcome all forms of contribution to make this project better\!

1.  **Fork** this repository.
2.  Create a new feature branch (e.g., `feat/your-feature`).
3.  Commit your changes.
4.  Create a new **Pull Request**.
